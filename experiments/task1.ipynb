{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"game\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"eudca\" has 5 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-77ae9b4c-761c-4769-860a-d9146b6320f5', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'index': 0}])], tool_call_id='call_LKjTzrN0dYZfndRRuH4A5lvL')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-77ae9b4c-761c-4769-860a-d9146b6320f5', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'index': 0}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-77ae9b4c-761c-4769-860a-d9146b6320f5', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LKjTzrN0dYZfndRRuH4A5lvL', 'index': 0}])], tool_call_id='call_LKjTzrN0dYZfndRRuH4A5lvL'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', name='get_word_length')]},\n",
       " {'output': 'The word \"eudca\" has 5 letters.',\n",
       "  'messages': [AIMessage(content='The word \"eudca\" has 5 letters.')]}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best option is: Restaurant with a great view\n"
     ]
    }
   ],
   "source": [
    "def select_best_option(text: str, options: list):\n",
    "    prompt = f\"Given the following text: '{text}', which of the following options is the best match?\\n\\nOptions:\\n\"\n",
    "    for idx, option in enumerate(options, 1):\n",
    "        prompt += f\"{idx}. {option}\\n\"\n",
    "\n",
    "    prompt += \"\\nPlease select the best option by number or name.\"\n",
    "\n",
    "    response = llm.predict(prompt)\n",
    "\n",
    "    selected_option = None\n",
    "    for option in options:\n",
    "        if option.lower() in response.lower():\n",
    "            selected_option = option\n",
    "            break\n",
    "\n",
    "    return selected_option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: i actually had a meeting come up on thursday\n",
      "This most likely aligns with |Reschedule an Existing Appointment|\n"
     ]
    }
   ],
   "source": [
    "text = \"i actually had a meeting come up on thursday\"\n",
    "options = [\"Schedule New Appointment\", \"Reschedule an Existing Appointment\", \"Not Applicable\"]\n",
    "\n",
    "best_option = select_best_option(text, options)\n",
    "print(f\"text input: {text}\")\n",
    "print(f\"This most likely aligns with |{best_option}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: who's better, Messi or Ronaldo?\n",
      "This most likely aligns with |Not Applicable|\n"
     ]
    }
   ],
   "source": [
    "text_input = \"who's better, Messi or Ronaldo?\"\n",
    "options_list = [\"Schedule New Appointment\", \"Reschedule an Existing Appointment\", \"Not Applicable\"]\n",
    "\n",
    "best_option = select_best_option(text_input, options_list)\n",
    "print(f\"text input: {text_input}\")\n",
    "print(f\"This most likely aligns with |{best_option}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: been having a fever lately\n",
      "This most likely aligns with |Schedule New Appointment|\n"
     ]
    }
   ],
   "source": [
    "text_input = \"been having a fever lately\"\n",
    "options_list = [\"Schedule New Appointment\", \"Reschedule an Existing Appointment\", \"Not Applicable\"]\n",
    "\n",
    "best_option = select_best_option(text_input, options_list)\n",
    "print(f\"text input: {text_input}\")\n",
    "print(f\"This most likely aligns with |{best_option}|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensions: build into a langchain agent to use a tool to context check and make sure that prompts such as the follow as properly classified/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: need a haircut soon\n",
      "This most likely aligns with |Schedule New Appointment|\n"
     ]
    }
   ],
   "source": [
    "#TODO should classifiy as \"Not Applicable\"\n",
    "text_input = \"need a haircut soon\"\n",
    "options_list = [\"Schedule New Appointment\", \"Reschedule an Existing Appointment\", \"Not Applicable\"]\n",
    "\n",
    "best_option = select_best_option(text_input, options_list)\n",
    "print(f\"text input: {text_input}\")\n",
    "print(f\"This most likely aligns with |{best_option}|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
